{"title":"Reflection on Using LLMs","markdown":{"yaml":{"title":"Reflection on Using LLMs"},"headingText":"Reflection on Using LLMs for Portfolio Development","containsRefs":false,"markdown":"\n\n\n*Word count: 475*\n\n## Evolution of My LLM Usage\n\nMy journey with Large Language Models (LLMs) has evolved significantly as I expanded my single-page portfolio into a comprehensive multi-page website. Initially, I approached LLMs as simple content generators, but through this process, I've developed a more nuanced understanding of their capabilities and limitations.\n\n### What Worked Better with Multi-Page Development\n\nThe multi-page format allowed me to leverage LLMs more effectively in several ways:\n\n**Structured Content Organization**: Breaking down my portfolio into distinct pages enabled me to provide more specific prompts to the LLM. Rather than requesting generic portfolio content, I could ask for targeted sections like \"Create a comprehensive skills page for a banking professional transitioning to data analytics.\" This specificity resulted in more relevant and detailed content.\n\n**Iterative Refinement**: The multi-page approach facilitated an iterative process where I could refine each section independently. I found that feeding the LLM with my revisions and asking for improvements on specific pages yielded increasingly polished content that better reflected my voice and experience.\n\n**Content Consistency**: I discovered that providing the LLM with previously generated sections helped maintain consistency across pages. By instructing the model to \"maintain the same tone and style as my about page,\" I achieved a cohesive feel throughout the site while still allowing each page to serve its unique purpose.\n\n**Specialized Formatting**: For pages requiring specific formats (like my resume), I found that providing the LLM with clear structural guidelines resulted in well-organized content that required minimal reformatting.\n\n## Ensuring Authenticity and Accuracy\n\nMaintaining the authenticity and accuracy of my portfolio was paramount. I implemented several strategies to achieve this:\n\n**Fact-Checking**: I meticulously reviewed all LLM-generated content against my actual experiences and credentials, correcting any inaccuracies or embellishments. This was particularly important for my resume and projects pages, where specific details needed to be precise.\n\n**Personal Voice Infusion**: After receiving initial drafts, I rewrote sections to better reflect my personal communication style and professional perspective. This involved adding specific anecdotes and insights that only I could provide.\n\n**Selective Content Integration**: Rather than accepting complete sections verbatim, I adopted a selective approach—incorporating helpful structural elements and phrasing while discarding generic content that didn't authentically represent me.\n\n**Contextual Adaptation**: I adapted the LLM-generated content to reflect the specific contexts of my experiences in Ghana and Canada, ensuring cultural and industry-specific nuances were accurately represented.\n\n## Conclusion\n\nMy approach to using LLMs has matured from viewing them as content creators to seeing them as collaborative thinking partners. The most effective strategy proved to be using LLMs for initial structure and ideas, then heavily customizing the content with my personal experiences and voice.\n\nThis process has not only resulted in a more authentic portfolio but has also deepened my understanding of how to effectively collaborate with AI tools—a skill that will undoubtedly be valuable in my future career in data analytics and digital transformation.","srcMarkdownNoYaml":"\n\n# Reflection on Using LLMs for Portfolio Development\n\n*Word count: 475*\n\n## Evolution of My LLM Usage\n\nMy journey with Large Language Models (LLMs) has evolved significantly as I expanded my single-page portfolio into a comprehensive multi-page website. Initially, I approached LLMs as simple content generators, but through this process, I've developed a more nuanced understanding of their capabilities and limitations.\n\n### What Worked Better with Multi-Page Development\n\nThe multi-page format allowed me to leverage LLMs more effectively in several ways:\n\n**Structured Content Organization**: Breaking down my portfolio into distinct pages enabled me to provide more specific prompts to the LLM. Rather than requesting generic portfolio content, I could ask for targeted sections like \"Create a comprehensive skills page for a banking professional transitioning to data analytics.\" This specificity resulted in more relevant and detailed content.\n\n**Iterative Refinement**: The multi-page approach facilitated an iterative process where I could refine each section independently. I found that feeding the LLM with my revisions and asking for improvements on specific pages yielded increasingly polished content that better reflected my voice and experience.\n\n**Content Consistency**: I discovered that providing the LLM with previously generated sections helped maintain consistency across pages. By instructing the model to \"maintain the same tone and style as my about page,\" I achieved a cohesive feel throughout the site while still allowing each page to serve its unique purpose.\n\n**Specialized Formatting**: For pages requiring specific formats (like my resume), I found that providing the LLM with clear structural guidelines resulted in well-organized content that required minimal reformatting.\n\n## Ensuring Authenticity and Accuracy\n\nMaintaining the authenticity and accuracy of my portfolio was paramount. I implemented several strategies to achieve this:\n\n**Fact-Checking**: I meticulously reviewed all LLM-generated content against my actual experiences and credentials, correcting any inaccuracies or embellishments. This was particularly important for my resume and projects pages, where specific details needed to be precise.\n\n**Personal Voice Infusion**: After receiving initial drafts, I rewrote sections to better reflect my personal communication style and professional perspective. This involved adding specific anecdotes and insights that only I could provide.\n\n**Selective Content Integration**: Rather than accepting complete sections verbatim, I adopted a selective approach—incorporating helpful structural elements and phrasing while discarding generic content that didn't authentically represent me.\n\n**Contextual Adaptation**: I adapted the LLM-generated content to reflect the specific contexts of my experiences in Ghana and Canada, ensuring cultural and industry-specific nuances were accurately represented.\n\n## Conclusion\n\nMy approach to using LLMs has matured from viewing them as content creators to seeing them as collaborative thinking partners. The most effective strategy proved to be using LLMs for initial structure and ideas, then heavily customizing the content with my personal experiences and voice.\n\nThis process has not only resulted in a more authentic portfolio but has also deepened my understanding of how to effectively collaborate with AI tools—a skill that will undoubtedly be valuable in my future career in data analytics and digital transformation."},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"include-in-header":["header.html"],"output-file":"reflection.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.29","theme":["cosmo"],"title":"Reflection on Using LLMs"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}